{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import PorterStemmer\n",
    "STOPS = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "\n",
    "## Clean texts\n",
    "def clean_text(text):\n",
    "    \"\"\"Takes in text and returns clean word list\"\"\"\n",
    "    output = re.sub('[^a-zA-Z ]', '', text).lower()\n",
    "    output = output.split(' ')\n",
    "    output = [o for o in output if o not in STOPS and len(o) > 0 and o[:4] != 'http']\n",
    "    return ' '.join(output)\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(clean_text)\n",
    "\n",
    "## Replace labels and split into train, test and validation sets\n",
    "def replace_labels(author):\n",
    "    label_dict = {'EAP': 0, 'HPL': 1, 'MWS': 2}\n",
    "    return label_dict[author]\n",
    "\n",
    "def replace_labels_vec(author):\n",
    "    label_dict = {'EAP': np.array([1, 0, 0]), 'HPL': np.array([0, 1, 0]), 'MWS': np.array([0, 0, 1])}\n",
    "    return label_dict[author]\n",
    "\n",
    "train_df['author_vector'] = train_df['author'].apply(replace_labels_vec)\n",
    "train_df['author'] = train_df['author'].apply(replace_labels)\n",
    "train_df, test_df = train_test_split(train_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split out sentences and form TF-IDF representations of text\n",
    "\n",
    "## Fit TF-DF transformer to training data\n",
    "count_vec = CountVectorizer()\n",
    "X_train_counts = count_vec.fit_transform(train_df['text'].tolist())\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "## Transform test and validation sets\n",
    "X_test_counts = count_vec.transform(test_df['text'].tolist())\n",
    "X_test = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "## Labels\n",
    "y_train = np.array(train_df['author'])\n",
    "y_test = np.array(test_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score = 0.8221924280150673\n",
      "clf__alpha: 0.08\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "## Grid search for alpha and bigrams/words\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)], \n",
    "    'clf__alpha': (0.001, 0.01, 0.05, 0.08, 0.1, 0.2, 0.5, 0.8, 1)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "gs_clf = gs_clf.fit(train_df['text'].tolist(), np.array(train_df['author']))\n",
    "\n",
    "## Print best score and parameters\n",
    "print(\"Best score = {}\".format(gs_clf.best_score_))\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"{}: {}\".format(param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cross entropy = 0.010503672089702935, train acc = 0.9982761923003256\n",
      "Test cross entropy = 0.1435777121526654, test acc = 0.8378447395301328\n"
     ]
    }
   ],
   "source": [
    "## Evaluating on train and test sets\n",
    "def cross_entropy(preds_mat, labels_mat):\n",
    "    \"\"\"both should by (3, ) vectors\"\"\"\n",
    "    return -np.mean(preds_mat * labels_mat)\n",
    "    \n",
    "## Training set\n",
    "train_preds = gs_clf.predict_log_proba(train_df['text'].tolist())\n",
    "train_labels = np.stack(train_df['author_vector'].tolist())\n",
    "train_Xent = cross_entropy(train_preds, train_labels)\n",
    "train_acc = np.mean(gs_clf.predict(train_df['text'].tolist()) == np.array(train_df['author']))\n",
    "print(\"Train cross entropy = {}, train acc = {}\".format(train_Xent, train_acc))\n",
    "\n",
    "## Test set\n",
    "test_preds = gs_clf.predict_log_proba(test_df['text'].tolist())\n",
    "test_labels = np.stack(test_df['author_vector'].tolist())\n",
    "test_Xent = cross_entropy(test_preds, test_labels)\n",
    "test_acc = np.mean(gs_clf.predict(test_df['text'].tolist()) == np.array(test_df['author']))\n",
    "print(\"Test cross entropy = {}, test acc = {}\".format(test_Xent, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   17.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score = 0.8310945400684406\n",
      "clf__alpha: 0.1\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "## Re-train on full training set (train+test)\n",
    "full_train_df = pd.concat([train_df, test_df])\n",
    "gs_clf_final = gs_clf.fit(full_train_df['text'].tolist(), np.array(full_train_df['author']))\n",
    "\n",
    "## Print best score and parameters\n",
    "print(\"Best score = {}\".format(gs_clf.best_score_))\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"{}: {}\".format(param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read in final test set and make predictions\n",
    "final_test_df = pd.read_csv('data/test.csv')\n",
    "final_test_df['text'] = final_test_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correct format for submission\n",
    "predictions = gs_clf_final.predict_proba(final_test_df['text'].tolist())\n",
    "final_test_df['EAP'] = predictions[:, 0]\n",
    "final_test_df['HPL'] = predictions[:, 1]\n",
    "final_test_df['MWS'] = predictions[:, 2]\n",
    "final_test_df = final_test_df.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save output to CSV file\n",
    "final_test_df.to_csv('data/second_submission.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
